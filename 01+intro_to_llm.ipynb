{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a628c194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typing-extensions>=4.0.0 (from beautifulsoup4)\n",
      "  Using cached typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Using cached typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
      "Installing collected packages: typing-extensions, soupsieve, beautifulsoup4\n",
      "\n",
      "   ------------- -------------------------- 1/3 [soupsieve]\n",
      "   -------------------------- ------------- 2/3 [beautifulsoup4]\n",
      "   -------------------------- ------------- 2/3 [beautifulsoup4]\n",
      "   -------------------------- ------------- 2/3 [beautifulsoup4]\n",
      "   -------------------------- ------------- 2/3 [beautifulsoup4]\n",
      "   -------------------------- ------------- 2/3 [beautifulsoup4]\n",
      "   -------------------------- ------------- 2/3 [beautifulsoup4]\n",
      "   -------------------------- ------------- 2/3 [beautifulsoup4]\n",
      "   -------------------------- ------------- 2/3 [beautifulsoup4]\n",
      "   ---------------------------------------- 3/3 [beautifulsoup4]\n",
      "\n",
      "Successfully installed beautifulsoup4-4.13.4 soupsieve-2.7 typing-extensions-4.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting google-genai\n",
      "  Using cached google_genai-1.23.0-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting anyio<5.0.0,>=4.8.0 (from google-genai)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth<3.0.0,>=2.14.1 (from google-genai)\n",
      "  Using cached google_auth-2.40.3-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting httpx<1.0.0,>=0.28.1 (from google-genai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic<3.0.0,>=2.0.0 (from google-genai)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting requests<3.0.0,>=2.28.1 (from google-genai)\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tenacity<9.0.0,>=8.2.3 (from google-genai)\n",
      "  Using cached tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting websockets<15.1.0,>=13.0.0 (from google-genai)\n",
      "  Using cached websockets-15.0.1-cp313-cp313-win_amd64.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in c:\\users\\mfuke\\onedrive\\bureau\\projects\\llm-engineering\\venv\\lib\\site-packages (from google-genai) (4.14.0)\n",
      "Collecting idna>=2.8 (from anyio<5.0.0,>=4.8.0->google-genai)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sniffio>=1.1 (from anyio<5.0.0,>=4.8.0->google-genai)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3.0.0,>=2.14.1->google-genai)\n",
      "  Using cached cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0.0,>=2.14.1->google-genai)\n",
      "  Using cached pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3.0.0,>=2.14.1->google-genai)\n",
      "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting certifi (from httpx<1.0.0,>=0.28.1->google-genai)\n",
      "  Using cached certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting httpcore==1.* (from httpx<1.0.0,>=0.28.1->google-genai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.0.0->google-genai)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3.0.0,>=2.0.0->google-genai)\n",
      "  Using cached pydantic_core-2.33.2-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.0.0->google-genai)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3.0.0,>=2.28.1->google-genai)\n",
      "  Using cached charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.28.1->google-genai)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting pyasn1>=0.1.3 (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-genai)\n",
      "  Using cached pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Using cached google_genai-1.23.0-py3-none-any.whl (223 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
      "Using cached cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp313-cp313-win_amd64.whl (105 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Using cached tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached websockets-15.0.1-cp313-cp313-win_amd64.whl (176 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Using cached pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: websockets, urllib3, typing-inspection, tenacity, sniffio, pydantic-core, pyasn1, idna, h11, charset_normalizer, certifi, cachetools, annotated-types, rsa, requests, pydantic, pyasn1-modules, httpcore, anyio, httpx, google-auth, google-genai\n",
      "\n",
      "   ----------------------------------------  0/22 [websockets]\n",
      "   ----------------------------------------  0/22 [websockets]\n",
      "   ----------------------------------------  0/22 [websockets]\n",
      "   ----------------------------------------  0/22 [websockets]\n",
      "   ----------------------------------------  0/22 [websockets]\n",
      "   ----------------------------------------  0/22 [websockets]\n",
      "   ----------------------------------------  0/22 [websockets]\n",
      "   ----------------------------------------  0/22 [websockets]\n",
      "   ----------------------------------------  0/22 [websockets]\n",
      "   ----------------------------------------  0/22 [websockets]\n",
      "   ----------------------------------------  0/22 [websockets]\n",
      "   ----------------------------------------  0/22 [websockets]\n",
      "   ----------------------------------------  0/22 [websockets]\n",
      "   ----------------------------------------  0/22 [websockets]\n",
      "   ----------------------------------------  0/22 [websockets]\n",
      "   ----------------------------------------  0/22 [websockets]\n",
      "   ----------------------------------------  0/22 [websockets]\n",
      "   - --------------------------------------  1/22 [urllib3]\n",
      "   - --------------------------------------  1/22 [urllib3]\n",
      "   - --------------------------------------  1/22 [urllib3]\n",
      "   - --------------------------------------  1/22 [urllib3]\n",
      "   - --------------------------------------  1/22 [urllib3]\n",
      "   - --------------------------------------  1/22 [urllib3]\n",
      "   - --------------------------------------  1/22 [urllib3]\n",
      "   - --------------------------------------  1/22 [urllib3]\n",
      "   ----- ----------------------------------  3/22 [tenacity]\n",
      "   ----- ----------------------------------  3/22 [tenacity]\n",
      "   ----- ----------------------------------  3/22 [tenacity]\n",
      "   --------- ------------------------------  5/22 [pydantic-core]\n",
      "   --------- ------------------------------  5/22 [pydantic-core]\n",
      "   ---------- -----------------------------  6/22 [pyasn1]\n",
      "   ---------- -----------------------------  6/22 [pyasn1]\n",
      "   ---------- -----------------------------  6/22 [pyasn1]\n",
      "   ---------- -----------------------------  6/22 [pyasn1]\n",
      "   ---------- -----------------------------  6/22 [pyasn1]\n",
      "   ------------ ---------------------------  7/22 [idna]\n",
      "   ------------ ---------------------------  7/22 [idna]\n",
      "   -------------- -------------------------  8/22 [h11]\n",
      "   -------------- -------------------------  8/22 [h11]\n",
      "   ---------------- -----------------------  9/22 [charset_normalizer]\n",
      "   ---------------- -----------------------  9/22 [charset_normalizer]\n",
      "   ---------------- -----------------------  9/22 [charset_normalizer]\n",
      "   -------------------- ------------------- 11/22 [cachetools]\n",
      "   ----------------------- ---------------- 13/22 [rsa]\n",
      "   ----------------------- ---------------- 13/22 [rsa]\n",
      "   ----------------------- ---------------- 13/22 [rsa]\n",
      "   ----------------------- ---------------- 13/22 [rsa]\n",
      "   ----------------------- ---------------- 13/22 [rsa]\n",
      "   ----------------------- ---------------- 13/22 [rsa]\n",
      "   ----------------------- ---------------- 13/22 [rsa]\n",
      "   ----------------------- ---------------- 13/22 [rsa]\n",
      "   ----------------------- ---------------- 13/22 [rsa]\n",
      "   ----------------------- ---------------- 13/22 [rsa]\n",
      "   ------------------------- -------------- 14/22 [requests]\n",
      "   ------------------------- -------------- 14/22 [requests]\n",
      "   --------------------------- ------------ 15/22 [pydantic]\n",
      "   --------------------------- ------------ 15/22 [pydantic]\n",
      "   --------------------------- ------------ 15/22 [pydantic]\n",
      "   --------------------------- ------------ 15/22 [pydantic]\n",
      "   --------------------------- ------------ 15/22 [pydantic]\n",
      "   --------------------------- ------------ 15/22 [pydantic]\n",
      "   --------------------------- ------------ 15/22 [pydantic]\n",
      "   --------------------------- ------------ 15/22 [pydantic]\n",
      "   --------------------------- ------------ 15/22 [pydantic]\n",
      "   --------------------------- ------------ 15/22 [pydantic]\n",
      "   --------------------------- ------------ 15/22 [pydantic]\n",
      "   --------------------------- ------------ 15/22 [pydantic]\n",
      "   --------------------------- ------------ 15/22 [pydantic]\n",
      "   --------------------------- ------------ 15/22 [pydantic]\n",
      "   --------------------------- ------------ 15/22 [pydantic]\n",
      "   ----------------------------- ---------- 16/22 [pyasn1-modules]\n",
      "   ----------------------------- ---------- 16/22 [pyasn1-modules]\n",
      "   ----------------------------- ---------- 16/22 [pyasn1-modules]\n",
      "   ----------------------------- ---------- 16/22 [pyasn1-modules]\n",
      "   ----------------------------- ---------- 16/22 [pyasn1-modules]\n",
      "   ----------------------------- ---------- 16/22 [pyasn1-modules]\n",
      "   ----------------------------- ---------- 16/22 [pyasn1-modules]\n",
      "   ----------------------------- ---------- 16/22 [pyasn1-modules]\n",
      "   ----------------------------- ---------- 16/22 [pyasn1-modules]\n",
      "   ----------------------------- ---------- 16/22 [pyasn1-modules]\n",
      "   ----------------------------- ---------- 16/22 [pyasn1-modules]\n",
      "   ----------------------------- ---------- 16/22 [pyasn1-modules]\n",
      "   ----------------------------- ---------- 16/22 [pyasn1-modules]\n",
      "   ----------------------------- ---------- 16/22 [pyasn1-modules]\n",
      "   ----------------------------- ---------- 16/22 [pyasn1-modules]\n",
      "   ----------------------------- ---------- 16/22 [pyasn1-modules]\n",
      "   ----------------------------- ---------- 16/22 [pyasn1-modules]\n",
      "   ----------------------------- ---------- 16/22 [pyasn1-modules]\n",
      "   ----------------------------- ---------- 16/22 [pyasn1-modules]\n",
      "   ----------------------------- ---------- 16/22 [pyasn1-modules]\n",
      "   ------------------------------ --------- 17/22 [httpcore]\n",
      "   ------------------------------ --------- 17/22 [httpcore]\n",
      "   ------------------------------ --------- 17/22 [httpcore]\n",
      "   ------------------------------ --------- 17/22 [httpcore]\n",
      "   ------------------------------ --------- 17/22 [httpcore]\n",
      "   -------------------------------- ------- 18/22 [anyio]\n",
      "   -------------------------------- ------- 18/22 [anyio]\n",
      "   -------------------------------- ------- 18/22 [anyio]\n",
      "   -------------------------------- ------- 18/22 [anyio]\n",
      "   -------------------------------- ------- 18/22 [anyio]\n",
      "   -------------------------------- ------- 18/22 [anyio]\n",
      "   -------------------------------- ------- 18/22 [anyio]\n",
      "   ---------------------------------- ----- 19/22 [httpx]\n",
      "   ---------------------------------- ----- 19/22 [httpx]\n",
      "   ---------------------------------- ----- 19/22 [httpx]\n",
      "   ---------------------------------- ----- 19/22 [httpx]\n",
      "   ---------------------------------- ----- 19/22 [httpx]\n",
      "   ------------------------------------ --- 20/22 [google-auth]\n",
      "   ------------------------------------ --- 20/22 [google-auth]\n",
      "   ------------------------------------ --- 20/22 [google-auth]\n",
      "   ------------------------------------ --- 20/22 [google-auth]\n",
      "   ------------------------------------ --- 20/22 [google-auth]\n",
      "   ------------------------------------ --- 20/22 [google-auth]\n",
      "   ------------------------------------ --- 20/22 [google-auth]\n",
      "   ------------------------------------ --- 20/22 [google-auth]\n",
      "   ------------------------------------ --- 20/22 [google-auth]\n",
      "   ------------------------------------ --- 20/22 [google-auth]\n",
      "   ------------------------------------ --- 20/22 [google-auth]\n",
      "   ------------------------------------ --- 20/22 [google-auth]\n",
      "   -------------------------------------- - 21/22 [google-genai]\n",
      "   -------------------------------------- - 21/22 [google-genai]\n",
      "   -------------------------------------- - 21/22 [google-genai]\n",
      "   -------------------------------------- - 21/22 [google-genai]\n",
      "   -------------------------------------- - 21/22 [google-genai]\n",
      "   -------------------------------------- - 21/22 [google-genai]\n",
      "   -------------------------------------- - 21/22 [google-genai]\n",
      "   -------------------------------------- - 21/22 [google-genai]\n",
      "   ---------------------------------------- 22/22 [google-genai]\n",
      "\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.9.0 cachetools-5.5.2 certifi-2025.6.15 charset_normalizer-3.4.2 google-auth-2.40.3 google-genai-1.23.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.10 pyasn1-0.6.1 pyasn1-modules-0.4.2 pydantic-2.11.7 pydantic-core-2.33.2 requests-2.32.4 rsa-4.9.1 sniffio-1.3.1 tenacity-8.5.0 typing-inspection-0.4.1 urllib3-2.5.0 websockets-15.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv\n",
    "%pip install beautifulsoup4\n",
    "%pip install google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a018dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from google import genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ebf395b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded the API key from .env file!\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "   \n",
    "if api_key:\n",
    "    print(\"Successfully loaded the API key from .env file!\")\n",
    "else:\n",
    "    print(\"API key found and looks good so far!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89c4c8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = genai.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "afb56d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! And a big, warm welcome to you! So glad you sent your very first message.\n",
      "\n",
      "How can I help you today? Or just here to say hi? 😊\n"
     ]
    }
   ],
   "source": [
    "message = \"Hello, This is my first ever message to you! Hi!\"\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\", contents=message\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65ab9304",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adcd9224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "May 28, 2025\n",
      "Connecting my courses – become an LLM expert and leader\n",
      "May 18, 2025\n",
      "2025 AI Executive Briefing\n",
      "April 21, 2025\n",
      "The Complete Agentic AI Engineering Course\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "ed = Website(\"https://edwarddonner.com\")\n",
    "print(ed.title)\n",
    "print(ed.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad87e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f237b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e457315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are looking at a website titled Home - Edward Donner\n",
      "The contents of this website is as follows; please provide a short summary of this website in markdown. If it includes news or announcements, then summarize these too.\n",
      "\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "May 28, 2025\n",
      "Connecting my courses – become an LLM expert and leader\n",
      "May 18, 2025\n",
      "2025 AI Executive Briefing\n",
      "April 21, 2025\n",
      "The Complete Agentic AI Engineering Course\n",
      "January 23, 2025\n",
      "LLM Workshop – Hands-on with Agents – resources\n",
      "Navigation\n",
      "Home\n",
      "Connect Four\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "print(user_prompt_for(ed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c99fe8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This website belongs to Edward Donner, co-founder and CTO of Nebula.io, an AI company applying LLMs to talent discovery and recruitment, which utilizes patented matching models. He previously founded untapt, an AI startup acquired in 2021.\n",
      "\n",
      "Edward has a strong interest in writing code and experimenting with LLMs, alongside hobbies like DJing and electronic music production. He mentions a project called \"Outsmart,\" described as an arena for LLMs to compete in diplomacy and deviousness.\n",
      "\n",
      "Recent posts/announcements include:\n",
      "\n",
      "*   **May 28, 2025:** Connecting my courses – become an LLM expert and leader\n",
      "*   **May 18, 2025:** 2025 AI Executive Briefing\n",
      "*   **April 21, 2025:** The Complete Agentic AI Engineering Course\n",
      "*   **January 23, 2025:** LLM Workshop – Hands-on with Agents – resources\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    config=types.GenerateContentConfig(\n",
    "        system_instruction=system_prompt),\n",
    "    contents=user_prompt_for(ed)\n",
    ")\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8012b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "\n",
    "client = genai.Client()\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = client.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        config=types.GenerateContentConfig(\n",
    "        system_instruction=system_prompt),\n",
    "        contents=user_prompt_for(website)\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6d6d2d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This website belongs to Ed Donner, co-founder and CTO of Nebula.io (an AI company applying AI to talent discovery, using proprietary LLMs and a patented matching model), and former founder/CEO of untapt. He enjoys writing code, experimenting with LLMs, DJing, and electronic music production. The site highlights his project \"Outsmart,\" an arena where LLMs compete in diplomacy.\\n\\nRecent posts and announcements include:\\n*   **May 28, 2025:** Connecting my courses – become an LLM expert and leader\\n*   **May 18, 2025:** 2025 AI Executive Briefing\\n*   **April 21, 2025:** The Complete Agentic AI Engineering Course\\n*   **January 23, 2025:** LLM Workshop – Hands-on with Agents – resources'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73c21779",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dff16874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Edward Donner is a co-founder and CTO of Nebula.io, an AI company applying LLMs to talent discovery and management. He previously founded untapt, an AI startup acquired in 2021. Ed has a passion for writing code, experimenting with LLMs, and also enjoys DJing and electronic music production. The site highlights his projects, including \"Outsmart,\" an arena for LLMs to engage in diplomacy, and \"Connect Four.\"\n",
       "\n",
       "**Recent Posts/Announcements:**\n",
       "*   **May 28, 2025:** Connecting my courses – become an LLM expert and leader\n",
       "*   **May 18, 2025:** 2025 AI Executive Briefing\n",
       "*   **April 21, 2025:** The Complete Agentic AI Engineering Course\n",
       "*   **January 23, 2025:** LLM Workshop – Hands-on with Agents – resources"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69de7bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Timbuk2 AI offers an Enterprise Generative AI Insights Engine designed to help businesses extract maximum value. This engine provides enterprise-grade, scaled market insights and strategic business intelligence to empower decision-making and streamline the path to value for enterprises."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://www.timbuk2.ai/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
